{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning Spectrally Normalized Deep Gaussian Process Regression Monte Carlo Simulation\n",
    "\n",
    "https://docs.gpytorch.ai/en/latest/examples/01_Exact_GPs/Simple_GP_Regression.html\n",
    "\n",
    "https://docs.gpytorch.ai/en/stable/examples/06_PyTorch_NN_Integration_DKL/KISSGP_Deep_Kernel_Regression_CUDA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.AL import AL\n",
    "from core.utils.plot_utils import results_plot, results_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE = 'example1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start structural reliability assessment and Active Learning procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 0\n",
      "Hyperparameters: [1], SN: True, act_fun: ReLU\n",
      "Best Loss: 1.627850353717804 at epoch 990. Training loss: 1.7121527194976807 and val. loss: 1.5435479879379272\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 1.6279\n",
      "  New best model found at fold 1:\n",
      "    layer sizes: [1], act fun: <class 'torch.nn.modules.activation.ReLU'>\n",
      "\n",
      "Fold: 1, Avg. Loss: 1.627850353717804\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\surrogate\\SNDGPR\\train.py:125: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 807\n",
      "Best Loss: 1.8751440048217773 at epoch 705. Training loss: 1.2895073890686035 and val. loss: 2.460780620574951\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 1.8751\n",
      "Fold: 2, Avg. Loss: 1.8751440048217773\n",
      "\n",
      "Early stopping at epoch 678\n",
      "Best Loss: 2.082586646080017 at epoch 576. Training loss: 1.976677656173706 and val. loss: 2.188495635986328\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 2.0826\n",
      "Fold: 3, Avg. Loss: 2.082586646080017\n",
      "\n",
      "Early stopping at epoch 747\n",
      "Best Loss: 1.8515983819961548 at epoch 645. Training loss: 2.0026485919952393 and val. loss: 1.7005481719970703\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 1.8516\n",
      "Fold: 4, Avg. Loss: 1.8515983819961548\n",
      "\n",
      "Early stopping at epoch 491\n",
      "Best Loss: 2.0924489498138428 at epoch 389. Training loss: 2.338533401489258 and val. loss: 1.8463644981384277\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 2.0924\n",
      "Fold: 5, Avg. Loss: 2.0924489498138428\n",
      "\n",
      "Average Loss across 5 folds: 1.9059256672859193\n",
      "\n",
      "obj fun (avg loss): 1.91 -> best fold: 1\n",
      "\n",
      "\n",
      "Hyperparameters: [1], SN: True, act_fun: ELU\n",
      "Best Loss: 0.9014582335948944 at epoch 999. Training loss: 1.2274973392486572 and val. loss: 0.5754191279411316\n",
      "  Training succeeded after 1 attempt(s).\n",
      "avg loss = 0.9015\n",
      "  New best model found at fold 1:\n",
      "    layer sizes: [1], act fun: <class 'torch.nn.modules.activation.ELU'>\n",
      "\n",
      "Fold: 1, Avg. Loss: 0.9014582335948944\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Results, History, Params \u001b[38;5;241m=\u001b[39m \u001b[43mAL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXAMPLE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\AL.py:65\u001b[0m, in \u001b[0;36mAL\u001b[1;34m(EXAMPLE)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m it \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# optimize hyperparameters\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m     Data \u001b[38;5;241m=\u001b[39m \u001b[43mhyper_params_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# use already optimized hyperparameters\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     layer_sizes, act_fun \u001b[38;5;241m=\u001b[39m optimization_variables(Data, Params, get_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\hyper_params_opt\\grid_search\\grid_search.py:25\u001b[0m, in \u001b[0;36mgrid_search\u001b[1;34m(Data, Params)\u001b[0m\n\u001b[0;32m     18\u001b[0m x_opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(grid, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     20\u001b[0m OptData \u001b[38;5;241m=\u001b[39m RuntimeData(\n\u001b[0;32m     21\u001b[0m     x\u001b[38;5;241m=\u001b[39mData\u001b[38;5;241m.\u001b[39mx,\n\u001b[0;32m     22\u001b[0m     g\u001b[38;5;241m=\u001b[39mData\u001b[38;5;241m.\u001b[39mg\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 25\u001b[0m f_opt, OptData \u001b[38;5;241m=\u001b[39m \u001b[43mobj_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m Data \u001b[38;5;241m=\u001b[39m keep_best(Data, OptData)\n\u001b[0;32m     28\u001b[0m Data\u001b[38;5;241m.\u001b[39mx_opt, Data\u001b[38;5;241m.\u001b[39mf_opt \u001b[38;5;241m=\u001b[39m x_opt, f_opt\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\hyper_params_opt\\objective_function.py:23\u001b[0m, in \u001b[0;36mobj_fun\u001b[1;34m(xx, OptData, Params)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHyperparameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_sizes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124mSN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mParams\u001b[38;5;241m.\u001b[39msurrogate\u001b[38;5;241m.\u001b[39mspectral_normalization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124mact_fun: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mact_fun\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;66;03m# Train the model with the sampled hyperparameters\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m         fobj, fold, KData \u001b[38;5;241m=\u001b[39m \u001b[43mkfold_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mact_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOptData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobj fun (avg loss): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfobj\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> best fold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m         fobj_all[idx] \u001b[38;5;241m=\u001b[39m fobj\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\K_fold_CV.py:52\u001b[0m, in \u001b[0;36mkfold_train\u001b[1;34m(layer_sizes, act_fun, Data, Params)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success \u001b[38;5;129;01mand\u001b[39;00m attempts \u001b[38;5;241m<\u001b[39m max_attempts:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         model, likelihood, avg_loss, train_losses, val_losses \\\n\u001b[1;32m---> 52\u001b[0m             \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mKData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m         success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Training was successful, exit loop\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Training succeeded after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempts\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m attempt(s).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\surrogate\\SNDGPR\\train.py:122\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(Data, Params, opt)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Training loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and val. loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_loss\n\u001b[1;32m--> 122\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Load the best model state\u001b[39;00m\n\u001b[0;32m    125\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_path)\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\Desktop\\DOC\\Artigo SN\\AL-SNDGPR-MCS\\core\\surrogate\\SNDGPR\\train.py:90\u001b[0m, in \u001b[0;36mtrain_model.<locals>.train\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     89\u001b[0m     val_output \u001b[38;5;241m=\u001b[39m model(val_x)\n\u001b[1;32m---> 90\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mmll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_g\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Save the best model based on validation and training loss\u001b[39;00m\n\u001b[0;32m     93\u001b[0m training_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpytorch\\module.py:31\u001b[0m, in \u001b[0;36mModule.__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, Distribution, LinearOperator]:\n\u001b[1;32m---> 31\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [_validate_module_outputs(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs]\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpytorch\\mlls\\exact_marginal_log_likelihood.py:82\u001b[0m, in \u001b[0;36mExactMarginalLogLikelihood.forward\u001b[1;34m(self, function_dist, target, *params, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN observation policy \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfill\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported by ExactMarginalLogLikelihood!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;66;03m# Get the log prob of the marginal distribution\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_other_terms(res, params)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Scale by the amount of data we have\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\T-GAMER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gpytorch\\distributions\\multivariate_normal.py:195\u001b[0m, in \u001b[0;36mMultivariateNormal.log_prob\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    192\u001b[0m covar \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39mevaluate_kernel()\n\u001b[0;32m    193\u001b[0m inv_quad, logdet \u001b[38;5;241m=\u001b[39m covar\u001b[38;5;241m.\u001b[39minv_quad_logdet(inv_quad_rhs\u001b[38;5;241m=\u001b[39mdiff\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), logdet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 195\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minv_quad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogdet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Results, History, Params = AL(EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_print(Results, History, Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_plot(Results, History, Params, EXAMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from core.utils.serialization_utils import pickle_load\n",
    "# pickle_load(EXAMPLE, ['Results', 'History', 'Params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
